snippet gym_import
	import gym
	import numpy as np

snippet gym_reset_wrapper
	class FireResetEnv(gym.Wrapper):
		def __init__(self, env):
			gym.Wrapper.__init__(self, env)
			assert env.unwrapped.get_action_meanings()[1] == 'FIRE'
			assert len(env.unwrapped.get_action_meanings()) >= 3

		def reset(self):
			self.env.reset()
			state, _, done, _ = self.env.step(1)
			if done: self.env.reset()
			state, _, done, _ = self.env.step(2)
			if done: self.env.reset()
			return state

		def step(self, action):
			return self.env.step(action)
snippet gym_episodic_life_wrapper
	class EpisodicLifeEnv(gym.Wrapper):
		def __init__(self, env):
			gym.Wrapper.__init__(self, env)
			self.lives = 0
			self.was_real_done = True

		def step(self, action):
			state, reward, done, info = self.env.step(action)
			lives = info['ale.lives']
			if lives < self.lives:
				done = True
			self.lives = lives
			return state, reward, done, info

		def reset(self):
			if self.lives == 0:
				state = self.env.reset()
			else:
				state, _, _, info = self.env.step(0)
				self.lives = info['ale.lives']
			return state
snippet gym_image_state_wrapper
	class MapState(gym.ObservationWrapper):
		def __init__(self, env, w, h):
			gym.ObservationWrapper.__init__(self, env)
			self.w, self.h = w, h
			self.observation_space = gym.spaces.Box(
				low=0, high=255, shape=(self.h, self.w))

		def _observation(self, obs):
			return self.process_image(obs, self.w, self.h)

		def process_image(state, input_width, input_height):
			# cropping important area of the state
			image = Image.fromarray(state).crop([0, 0, 100, 100])
			image = image.resize([input_width, input_height], Image.NEAREST).convert('L')
			img = np.array(image, dtype=np.uint8)
		return img
snippet gym_fire_live_loss_wrapper
	class FireLiveLoss(gym.Wrapper):
	def __init__(self, env):
		gym.Wrapper.__init__(self, env)
		self.lives = 0

	def step(self, action):
		state, reward, done, info = self.env.step(action)
		lives = info['ale.lives']
		if lives < self.lives:
			state, _, _, info = self.env.step(0)
			state, _, _, info = self.env.step(1)
		self.lives = lives
		return state, reward, done, info
snippet gym_history_state_wrapper
	class HistoryStatesEnv(gym.Wrapper):
		def __init__(self, env, history_size):
			gym.Wrapper.__init__(self, env)
			self.history = deque(maxlen=history_size)

		def observation(self, obs):
			return self.env.observation(obs)

		def reset(self):
			state = self.env.reset()
			empty = np.zeros(self.observation_space.shape, np.uint8)
			for _ in range(self.history.maxlen - 1):
				self.history.append(empty)
				self.history.append(state)
			return self._history()

		def _history(self):
			return np.stack(self.history, axis=2)

		def step(self, action):
			state, reward, done, info = self.env.step(action)
			self.history.append(state)
			return self._history(), reward, done, info
